{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "75ca41be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "import re\n",
    "import numpy as np\n",
    "from openai.embeddings_utils import get_embedding\n",
    "openai.organization = \"\"\n",
    "openai.api_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9cedcf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trump = pd.read_csv('https://drive.google.com/uc?export=download&id=1xRKHaP-QwACMydlDnyFPEaFdtskJuBa6')\n",
    "trump.text = trump.apply(lambda row: re.sub(r\"http\\S+\", \"\", row.text).lower(), 1)\n",
    "trump.text = trump.apply(lambda row: \" \".join(filter(lambda x:x[0]!=\"@\", row.text.split())), 1)\n",
    "trump.text = trump.apply(lambda row: \" \".join(re.sub(\"[^a-zA-Z]+\", \" \", row.text).split()), 1)\n",
    "trump = trump.loc[(trump.isRetweet == \"f\") & (trump.text != \"\"), :]\n",
    "timestamps = trump.date.to_list()\n",
    "tweets = trump.text.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1542c35b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45355"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "799ddd98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>republicans and democrats have both created ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i was thrilled to be back in the great city of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets\n",
       "0  republicans and democrats have both created ou...\n",
       "1  i was thrilled to be back in the great city of..."
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame (tweets, columns = ['tweets'])\n",
    "df = df.dropna() \n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "40eef0d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45355"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eb01c485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding model parameters\n",
    "##not need if doing it parallel\n",
    "embedding_model = \"text-embedding-ada-002\"\n",
    "embedding_encoding = \"cl100k_base\"  # this the encoding for text-embedding-ada-002\n",
    "max_tokens = 8000  # the maximum for text-embedding-ada-002 is 8191\n",
    "encoding = tiktoken.get_encoding(embedding_encoding)\n",
    "df[\"n_tokens\"] = df.tweets.apply(lambda x: len(encoding.encode(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c2c6f0f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1007933"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df.n_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c8c611d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>n_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44390</th>\n",
       "      <td>but should be much higher than that if twitter...</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44391</th>\n",
       "      <td>the best thing ever to happen to twitter is do...</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44392</th>\n",
       "      <td>harley davidson has struggled with tariffs wit...</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44393</th>\n",
       "      <td>dumb and sick a really bad show with low ratin...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44394</th>\n",
       "      <td>sorry to say but is by far the best of the mor...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45350</th>\n",
       "      <td>iran never won a war but never lost a negotiation</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45351</th>\n",
       "      <td>thank you to the washington examiner the list ...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45352</th>\n",
       "      <td>one of my greatest honors was to have gotten c...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45353</th>\n",
       "      <td>just signed an order to support the workers of...</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45354</th>\n",
       "      <td>suburban women want safety amp security joe bi...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>965 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweets  n_tokens\n",
       "44390  but should be much higher than that if twitter...        37\n",
       "44391  the best thing ever to happen to twitter is do...        46\n",
       "44392  harley davidson has struggled with tariffs wit...        52\n",
       "44393  dumb and sick a really bad show with low ratin...        53\n",
       "44394  sorry to say but is by far the best of the mor...        50\n",
       "...                                                  ...       ...\n",
       "45350  iran never won a war but never lost a negotiation        10\n",
       "45351  thank you to the washington examiner the list ...        12\n",
       "45352  one of my greatest honors was to have gotten c...        22\n",
       "45353  just signed an order to support the workers of...        44\n",
       "45354  suburban women want safety amp security joe bi...        15\n",
       "\n",
       "[965 rows x 2 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dfs = np.array_split(df,47)\n",
    "split_dfs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5189c5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "\n",
      "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
      "https://nalepae.github.io/pandarallel/troubleshooting/\n"
     ]
    }
   ],
   "source": [
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b063e89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_apply(x):\n",
    "    import openai\n",
    "    from openai.embeddings_utils import get_embedding\n",
    "    embedding_model = \"text-embedding-ada-002\"\n",
    "    openai.organization = \"\"\n",
    "    openai.api_key = \"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\"\n",
    "    openai.organization = \"\"\n",
    "    return get_embedding(x, engine=embedding_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a425a218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----subset 0\n",
      "---- starting 1681107906.5701902\n",
      "--- 59.42798328399658 seconds ---\n",
      "----subset 1\n",
      "---- starting 1681107965.9981735\n",
      "--- 40.44194531440735 seconds ---\n",
      "----subset 2\n",
      "---- starting 1681108006.4411182\n",
      "--- 40.017064809799194 seconds ---\n",
      "----subset 3\n",
      "---- starting 1681108046.458183\n",
      "--- 38.99197006225586 seconds ---\n",
      "----subset 4\n",
      "---- starting 1681108085.450153\n",
      "--- 37.5728497505188 seconds ---\n",
      "----subset 5\n",
      "---- starting 1681108123.0230029\n",
      "--- 37.270559787750244 seconds ---\n",
      "----subset 6\n",
      "---- starting 1681108160.2935627\n",
      "--- 36.35963702201843 seconds ---\n",
      "----subset 7\n",
      "---- starting 1681108196.6541836\n",
      "--- 32.887691259384155 seconds ---\n",
      "----subset 8\n",
      "---- starting 1681108229.541875\n",
      "--- 35.75722551345825 seconds ---\n",
      "----subset 9\n",
      "---- starting 1681108265.3001\n",
      "--- 30.671090364456177 seconds ---\n",
      "----subset 10\n",
      "---- starting 1681108295.9711905\n",
      "--- 36.39570450782776 seconds ---\n",
      "----subset 11\n",
      "---- starting 1681108332.3679004\n",
      "--- 38.0749785900116 seconds ---\n",
      "----subset 12\n",
      "---- starting 1681108370.442879\n",
      "--- 36.124346017837524 seconds ---\n",
      "----subset 13\n",
      "---- starting 1681108406.567225\n",
      "--- 38.34968900680542 seconds ---\n",
      "----subset 14\n",
      "---- starting 1681108444.916914\n",
      "--- 39.80095100402832 seconds ---\n",
      "----subset 15\n",
      "---- starting 1681108484.7188647\n",
      "--- 41.346314668655396 seconds ---\n",
      "----subset 16\n",
      "---- starting 1681108526.0651793\n",
      "--- 40.84379506111145 seconds ---\n",
      "----subset 17\n",
      "---- starting 1681108566.9089744\n",
      "--- 40.38204288482666 seconds ---\n",
      "----subset 18\n",
      "---- starting 1681108607.2910173\n",
      "--- 41.75989651679993 seconds ---\n",
      "----subset 19\n",
      "---- starting 1681108649.0509138\n",
      "--- 44.208043575286865 seconds ---\n",
      "----subset 20\n",
      "---- starting 1681108693.2589574\n",
      "--- 41.72923016548157 seconds ---\n",
      "----subset 21\n",
      "---- starting 1681108734.9881876\n",
      "--- 45.86087465286255 seconds ---\n",
      "----subset 22\n",
      "---- starting 1681108780.8500602\n",
      "--- 54.090930223464966 seconds ---\n",
      "----subset 23\n",
      "---- starting 1681108834.9409904\n",
      "--- 50.44619393348694 seconds ---\n",
      "----subset 24\n",
      "---- starting 1681108885.3871844\n",
      "--- 41.12078785896301 seconds ---\n",
      "----subset 25\n",
      "---- starting 1681108926.5079722\n",
      "--- 43.39432668685913 seconds ---\n",
      "----subset 26\n",
      "---- starting 1681108969.902299\n",
      "--- 39.76175260543823 seconds ---\n",
      "----subset 27\n",
      "---- starting 1681109009.6640515\n",
      "--- 71.74207472801208 seconds ---\n",
      "----subset 28\n",
      "---- starting 1681109081.407126\n",
      "--- 63.673938512802124 seconds ---\n",
      "----subset 29\n",
      "---- starting 1681109145.0810645\n",
      "--- 37.358076095581055 seconds ---\n",
      "----subset 30\n",
      "---- starting 1681109182.4391406\n",
      "--- 38.53935194015503 seconds ---\n",
      "----subset 31\n",
      "---- starting 1681109220.9784925\n",
      "--- 37.29809832572937 seconds ---\n",
      "----subset 32\n",
      "---- starting 1681109258.2765908\n",
      "--- 38.38647437095642 seconds ---\n",
      "----subset 33\n",
      "---- starting 1681109296.6630652\n",
      "--- 40.454917430877686 seconds ---\n",
      "----subset 34\n",
      "---- starting 1681109337.1179826\n",
      "--- 64.59521818161011 seconds ---\n",
      "----subset 35\n",
      "---- starting 1681109401.7132008\n",
      "--- 55.051839113235474 seconds ---\n",
      "----subset 36\n",
      "---- starting 1681109456.7660398\n",
      "--- 50.56150722503662 seconds ---\n",
      "----subset 37\n",
      "---- starting 1681109507.3285465\n",
      "--- 45.5354483127594 seconds ---\n",
      "----subset 38\n",
      "---- starting 1681109552.8639948\n",
      "--- 46.03819680213928 seconds ---\n",
      "----subset 39\n",
      "---- starting 1681109598.9021916\n",
      "--- 35.73897886276245 seconds ---\n",
      "----subset 40\n",
      "---- starting 1681109634.6411705\n",
      "--- 38.31521773338318 seconds ---\n",
      "----subset 41\n",
      "---- starting 1681109672.9563882\n",
      "--- 36.76960325241089 seconds ---\n",
      "----subset 42\n",
      "---- starting 1681109709.7259915\n",
      "--- 44.315285444259644 seconds ---\n",
      "----subset 43\n",
      "---- starting 1681109754.041277\n",
      "--- 36.05462408065796 seconds ---\n",
      "----subset 44\n",
      "---- starting 1681109790.095901\n",
      "--- 36.454845666885376 seconds ---\n",
      "----subset 45\n",
      "---- starting 1681109826.5517466\n",
      "--- 40.768861293792725 seconds ---\n",
      "----subset 46\n",
      "---- starting 1681109867.320608\n",
      "--- 37.005292892456055 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "for i in range(len(split_dfs)):\n",
    "    sdf = split_dfs[i]\n",
    "    start_time = time.time()\n",
    "    print(\"----subset %s\" %i)\n",
    "    print(\"---- starting %s\" %(start_time))\n",
    "    sdf[\"embedding\"] = sdf[\"tweets\"].parallel_apply(process_apply)\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    sdf[\"embedding\"].head(2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5467b7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultdf = pd.concat(split_dfs)\n",
    "resultdf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ee774662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45355"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(resultdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "869dcb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultdf.to_csv(\"trump_tweet_embedded.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b975e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "emb = np.array([ast.literal_eval(x) for x in df[\"embedding\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0600a780",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb.shape\n",
    "np.save(\"trump_twitter_np_ada.npy\", emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d8817e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb25d233",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################Chaning to test set########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98858ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testdf = dfs[0].iloc[0:10].copy()\n",
    "# len(testdf)\n",
    "# ###these works\n",
    "# #testdf[\"embedding\"] = testdf[\"tweets\"].apply(lambda x: get_embedding(x, engine=embedding_model))\n",
    "# def process_apply(x):\n",
    "#     import openai\n",
    "#     from openai.embeddings_utils import get_embedding\n",
    "#     embedding_model = \"text-embedding-ada-002\"\n",
    "#     openai.organization = \"\"\n",
    "#     openai.api_key = \"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\"\n",
    "#     openai.organization = \"\"\n",
    "#     return get_embedding(x, engine=embedding_model)\n",
    "# #testdf[\"embedding\"] = testdf[\"tweets\"].apply(process_apply)\n",
    "# testdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3523750a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##this work\n",
    "#testdf[\"embedding\"] = testdf[\"tweets\"].parallel_apply(process_apply)\n",
    "#testdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ee24e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_dfs = np.array_split(testdf,10)\n",
    "# split_dfs[0].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb662a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# for i in range(len(split_dfs)):\n",
    "#     sdf = split_dfs[i]\n",
    "#     start_time = time.time()\n",
    "#     print(\"----subset %s\" %i)\n",
    "#     print(\"---- starting %s\" %(start_time))\n",
    "#     sdf[\"embedding\"] = sdf[\"tweets\"].parallel_apply(process_apply)\n",
    "#     print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "#     sdf[\"embedding\"].head(2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0704d784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d4e852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9f3011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939d8e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c4c5e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5997568",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
